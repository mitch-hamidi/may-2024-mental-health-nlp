{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Analyzing the Manual Coded Data\n"]},{"cell_type":"markdown","metadata":{},"source":["Sentiment Analysis: Analyzing the sentiment of posts helps us understand the emotional tone expressed in the text. This could be particularly useful in identifying posts that express treatments and treatment outcomes associated with mental health issues."]},{"cell_type":"markdown","metadata":{},"source":["[Link to Mental Disorders Identification Reddit NLP dataset](https://www.kaggle.com/datasets/kamaruladha/mental-disorders-identification-reddit-nlp)"]},{"cell_type":"markdown","metadata":{},"source":["# CODE"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T08:39:07.603308Z","iopub.status.busy":"2024-04-26T08:39:07.602108Z","iopub.status.idle":"2024-04-26T08:39:07.610946Z","shell.execute_reply":"2024-04-26T08:39:07.608859Z","shell.execute_reply.started":"2024-04-26T08:39:07.603257Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","import matplotlib.pyplot  as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T08:39:07.613363Z","iopub.status.busy":"2024-04-26T08:39:07.612857Z","iopub.status.idle":"2024-04-26T08:39:27.372568Z","shell.execute_reply":"2024-04-26T08:39:27.370656Z","shell.execute_reply.started":"2024-04-26T08:39:07.613312Z"},"trusted":true},"outputs":[],"source":["df1=pd.read_csv('data/sample_posts_manual_coding_2.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Looking at the manual coded data\n","As of 5/18 at 6:13 AM I have manually coded the first 600 entries of this csv file, which contains all posts from the BPD subreddit between 01-01-2022 and 02-01-2022. There are 1882 posts in total, so this is roughly 1/3 of the total. The CSV file is not in chronological order, however.\n","\n","The column 'self' refers to whether or not the person with (diagnosed or suspected) BPD is the poster, or someone else. This is defaulted to 1, and is 0 if the post is about someone else.\n","The column 'is_relevant' takes an inclusive view, so includes any post which discusses therapy or medication in any way. This is defaulted to zero, and is set to 1 if the post is relevant. The majority of these mentions are only done in passing, so I created a new column called 'highly_relevant', which only includes posts which mention a specific type of therapy/medication and some type of outcome. This is defaulted to null, and set to 1 if the post is highly relevant.\n","\n","From reading through 500 of these posts, here are some common patterns:\n","1. There are relatively few posts which go into detail about treatments. I suspect the 'is_relevant' column will not be particularly useful, but the 'highly_relevant' one might be better.\n","2. There may be other research questions which this data set is better suited to address, since there are a lot of commonalities between the posts.\n","3. A number of posts mention that other posts are getting removed or deleted. Since I have already removed those from the data (and wouldn't be able to analyze them anyway), we are getting a filtered sample."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T08:39:27.409377Z","iopub.status.busy":"2024-04-26T08:39:27.408634Z","iopub.status.idle":"2024-04-26T08:39:27.416488Z","shell.execute_reply":"2024-04-26T08:39:27.414900Z","shell.execute_reply.started":"2024-04-26T08:39:27.409342Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1882, 9)\n"]}],"source":["print(df1.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-26T08:39:27.420328Z","iopub.status.busy":"2024-04-26T08:39:27.418983Z","iopub.status.idle":"2024-04-26T08:39:27.773778Z","shell.execute_reply":"2024-04-26T08:39:27.772224Z","shell.execute_reply.started":"2024-04-26T08:39:27.420274Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1882 entries, 0 to 1881\n","Data columns (total 9 columns):\n"," #   Column           Non-Null Count  Dtype \n","---  ------           --------------  ----- \n"," 0   title            1882 non-null   object\n"," 1   selftext         1882 non-null   object\n"," 2   created_utc      1882 non-null   int64 \n"," 3   over_18          1882 non-null   bool  \n"," 4   subreddit        1882 non-null   object\n"," 5   date_created     1882 non-null   object\n"," 6   self             1882 non-null   int64 \n"," 7   is_relevant      1882 non-null   int64 \n"," 8   highly_relevant  21 non-null     object\n","dtypes: bool(1), int64(3), object(5)\n","memory usage: 119.6+ KB\n"]}],"source":["df1.info()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["106"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["## Counting the relevant posts\n","\n","df1[df1['is_relevant'] != 0]['is_relevant'].count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Of the first 600 posts in this sample, there are 106 relevant posts and 20 highly relevant posts (the last non-null entry is a marker for the last post which was coded)."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_44149/1426566498.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n","You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n","A typical example is when you are setting values in a column of a DataFrame, like:\n","\n","df[\"col\"][row_indexer] = value\n","\n","Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","\n","  df_coded.highly_relevant[598] = np.nan\n","/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_44149/1426566498.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_coded.highly_relevant[598] = np.nan\n","/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_44149/1426566498.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_coded['highly_relevant'] = df_coded['highly_relevant'].fillna(0)\n"]}],"source":["posts_analyzed = 600\n","\n","df_coded = df1.head(posts_analyzed)\n","\n","## Removing the marker of where things were left off.\n","\n","df_coded.highly_relevant[598] = np.nan\n","\n","df_coded['highly_relevant'] = df_coded['highly_relevant'].fillna(0)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Distinct entries in column 'highly_relevant':\n","[0 '1']\n"]}],"source":["distinct_entries = df_coded['highly_relevant'].unique()\n","\n","# Print the distinct entries\n","print(\"Distinct entries in column 'highly_relevant':\")\n","print(distinct_entries)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_44149/686748163.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_coded['highly_relevant'] = df_coded['highly_relevant'].astype(int)\n"]}],"source":["## Note that the '1's are being read as strings. We'll fix that now\n","\n","df_coded['highly_relevant'] = df_coded['highly_relevant'].astype(int)"]},{"cell_type":"markdown","metadata":{},"source":["#### First attempts at building NLP models\n","Probably going to fail miserably, but there's only one way to find out..."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["## pip install nltk\n","\n","## nltk.download('stopwords')\n","\n","## nltk.download('wordnet') \n","\n","## For the life of me, I could not get this to work and had to manually download the folders and put them in the folder by hand.\n","## Hopefully, you have better luck with this.\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report, make_scorer, accuracy_score\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"markdown","metadata":{},"source":["#### Creating a single column with all the text and removing stopwords"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_44149/1986706231.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_coded['combined_text'] = df_coded['title'] + ' ' + df_coded['selftext']\n","/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_44149/1986706231.py:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_coded['processed_text'] = df_coded['combined_text'].apply(preprocess_text)\n"]}],"source":["# Combine text columns into a single column\n","df_coded['combined_text'] = df_coded['title'] + ' ' + df_coded['selftext']\n","\n","# Text preprocessing function\n","def preprocess_text(text):\n","    stop_words = set(stopwords.words('english'))\n","    lemmatizer = WordNetLemmatizer()\n","    \n","    # Tokenization\n","    tokens = text.split()\n","    \n","    # Lowercase and remove stopwords\n","    tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n","    \n","    # Lemmatization\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","    \n","    return ' '.join(tokens)\n","\n","# Apply preprocessing to the combined text column\n","df_coded['processed_text'] = df_coded['combined_text'].apply(preprocess_text)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### The 0th level model"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross-validation scores: [0.96875 0.96875 0.9625 ]\n","Mean cross-validation score: 0.9666666666666667\n","\n","Evaluation on the hold-out set:\n","              precision    recall  f1-score   support\n","\n","           0       0.97      1.00      0.98       116\n","           1       0.00      0.00      0.00         4\n","\n","    accuracy                           0.97       120\n","   macro avg       0.48      0.50      0.49       120\n","weighted avg       0.93      0.97      0.95       120\n","\n"]},{"name":"stderr","output_type":"stream","text":["/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["# Split the data into a training and hold-out set\n","X = df_coded['processed_text']\n","y = df_coded['highly_relevant']\n","\n","X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, stratify=y)\n","\n","# Create a text classification pipeline\n","pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer()),\n","    ('classifier', MultinomialNB())\n","])\n","\n","# Perform k-fold cross-validation on the training set\n","kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kfold, scoring='accuracy')\n","\n","print(f\"Cross-validation scores: {cv_scores}\")\n","print(f\"Mean cross-validation score: {cv_scores.mean()}\")\n","\n","# Train the model on the entire training set and evaluate on the hold-out set\n","pipeline.fit(X_train, y_train)\n","y_pred_holdout = pipeline.predict(X_holdout)\n","\n","print(\"\\nEvaluation on the hold-out set:\")\n","print(classification_report(y_holdout, y_pred_holdout))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["This is not working at all. Because the columns are so imbalanced, the model just returns 0 (not 'highly_relevant'). So let's start changing things to better reward finding 1s."]},{"cell_type":"markdown","metadata":{},"source":["#### A slightly better baseline"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Evaluation on the hold-out set with adjusted threshold:\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.81      0.89       116\n","           1       0.12      0.75      0.21         4\n","\n","    accuracy                           0.81       120\n","   macro avg       0.55      0.78      0.55       120\n","weighted avg       0.96      0.81      0.87       120\n","\n"]}],"source":["X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)\n","\n","# Create a text classification pipeline\n","pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer()),\n","    ('classifier', MultinomialNB())\n","])\n","\n","# Perform k-fold cross-validation on the training set\n","kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Train the model on the entire training set and evaluate on the hold-out set\n","pipeline.fit(X_train, y_train)\n","y_pred_prob_holdout = pipeline.predict_proba(X_holdout)[:, 1]  # Get probabilities for the positive class\n","\n","# Adjust the threshold\n","threshold = 0.001  # Example threshold less than 0.5 to increase sensitivity\n","y_pred_holdout = (y_pred_prob_holdout >= threshold).astype(int)\n","\n","print(\"\\nEvaluation on the hold-out set with adjusted threshold:\")\n","print(classification_report(y_holdout, y_pred_holdout))"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Entries from the holdout set that the model predicted as positive:\n","570    book movie recommendation i've recently gotten...\n","316    got second opinion confirmed bpd left sub firs...\n","451    using sleep coping mechanism past 2 year copin...\n","285    i’m quit job mental health bad feel guilty lik...\n","103    shfkfhfj boy showing slight interest i’m prett...\n","17     ever stop? pretty much always go like this: so...\n","269    quiet bpd day like today inside out, organ bur...\n","137    ex boyfriend fetish messaged girl reddit about...\n","367    bipolar bdp well today first appointment new t...\n","376    really get diagnosed 25? told psychologist i’v...\n","356    better mood swing bad im getting better managi...\n","400    re: removed post hi all! we've lot people reac...\n","117    chaos embodied borderline personality disorder...\n","47     advice overcoming future failure hey everyone,...\n","565    whats wrong ? posted long ago best friend bpd ...\n","75     diagnosed bpd tendency mean full blown disorde...\n","126    period make bpd unbearable.. advice? i'm daily...\n","90     long diagnosis take diagnosed? hi i’m posting ...\n","375    exactly therapy feel get therapist get dbt wor...\n","305    don’t know much longer ran medication month ag...\n","529    like fp differences, spiral negativity talk sa...\n","563    r/bpd monthly town hall think r/bpd doing? que...\n","3      cope family doesn’t believe mental illness dia...\n","40     feeling hella confident feel hella self hatred...\n","279    serious fever, issue ache lungs. stressed tf f...\n","Name: processed_text, dtype: object\n","\n","Actual labels for the positive entries:\n","570    0\n","316    0\n","451    0\n","285    0\n","103    0\n","17     0\n","269    0\n","137    0\n","367    1\n","376    0\n","356    0\n","400    0\n","117    0\n","47     0\n","565    0\n","75     0\n","126    1\n","90     1\n","375    0\n","305    0\n","529    0\n","563    0\n","3      0\n","40     0\n","279    0\n","Name: highly_relevant, dtype: int64\n"]}],"source":["# Filter the holdout set for entries predicted as positive\n","positive_entries = X_holdout[y_pred_holdout == 1]\n","\n","# Display the positive entries from the holdout set\n","print(\"\\nEntries from the holdout set that the model predicted as positive:\")\n","print(positive_entries)\n","\n","# Additionally, show the actual labels for these entries\n","positive_labels = y_holdout[y_pred_holdout == 1]\n","print(\"\\nActual labels for the positive entries:\")\n","print(positive_labels)"]},{"cell_type":"markdown","metadata":{},"source":["There are a ton of false positives, but we seem to be doing a reasonably job of finding the relevant posts. More importantly, we can use this as a baseline to improve upon."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2671334,"sourceId":4579285,"sourceType":"datasetVersion"},{"datasetId":4828752,"sourceId":8161593,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
