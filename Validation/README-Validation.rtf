{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 This folder contains two csv files called \'93FinalEvaluatedRelevanceValidation\'94 and \'93FinalEvaluatedSentimentValdation.\'94 The two files contain Reddit content that has been (1) cleaned, formatted, and run through the functions coded in the notebook \'93LoadDataandClean\'94 in the \'93Cleaning_Data_Exploration_and_Modeling\'94 folder as well as (2) had values of \'93sentiment\'94 and \'93relevance\'94 validated manually. Here, when we say \'93sentiment\'94 we mean whether a post\'92s author expressed a positive or negative feeling toward their treatment plan and for \'93relevance\'94 we mean whether a post\'92s content was deemed relevant to the topics of diagnosis and treatment of borderline personality disorder. There are two other csv files called \'93validandpredictedrelevancytogther\'94 and \'93validandpredictedsentimenttogether\'94 that contain the validated users\'92 sentiments (0 for negative recommendation and 1 for positive recommendation) and validated relevance of post (0 for irrelevant and 1 for relevant) appearing along side the predicted sentiments (\'93Recommendation_Score\'94 with the same scores of 0 for negative recommendation and 1 for positive recommendation) and relevance (\'93Relevancy_Score\'94 with scores of 4,3,2,1 for differing levels of relevancy as defined by the functions coded in Python and 0 for irrelevant posts) that were predicted. \
\
\
There are several Jupyter notebooks starting with the words \'93DecisionTree\'85\'94, \'93NaiveBayes...\'94, \'93SVM\'85\'94, and \'93Random\'85\'94 which take the cleaned, formatted, and functioned validated Reddit posts and in put them into the predictive models mentioned in similar notebooks in the \'93Cleaning_Data_Exploration_and_Modeling\'94 folder. You\'92ll notice that precision, accuracy, recall, the f1 score and a confusion matrix are produced for each evaluation. \
\
\
Finally, there is a Jupyter notebook called \'93ComparingTrueandPredictedSentimentandRelevance\'94 which takes the true and predicted values from the csv files \'93validandpredictedrelevancytogther\'94 and \'93validandpredictedsentimenttogether\'94 directly calculates precision, accuracy, and recall. }