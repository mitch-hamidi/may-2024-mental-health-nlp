{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with variations of the keyword model  \n",
    "\n",
    "In this file, I'm trying to experiment with variations of the keyword model to see which one has the best performance. For different random settings, the numbers will be a bit different, so we should probably err on the side of simpler models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "class TextRelevanceModel:\n",
    "    def __init__(self, keyword_categories, general_keywords=None, negative_keywords=None, model=None):\n",
    "        self.keyword_categories = keyword_categories\n",
    "        self.general_keywords = general_keywords if general_keywords is not None else []\n",
    "        self.negative_keywords = negative_keywords if negative_keywords is not None else []\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = model if model is not None else LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    def keyword_count(self, text, keywords):\n",
    "        return sum(1 for word in text.lower().split() if word in keywords)\n",
    "    \n",
    "    def prepare_data(self, df, text_column, fit_vectorizer=False):\n",
    "        # Preprocess text data (convert to lowercase)\n",
    "        df[text_column] = df[text_column].str.lower()\n",
    "\n",
    "        keyword_counts = pd.DataFrame()\n",
    "        \n",
    "        for category, keywords in self.keyword_categories.items():\n",
    "            keyword_counts[category + '_count'] = df[text_column].apply(lambda x: self.keyword_count(x, keywords))\n",
    "        \n",
    "        keyword_counts['negative_keyword_count'] = df[text_column].apply(lambda x: self.keyword_count(x, self.negative_keywords))\n",
    "        \n",
    "        if fit_vectorizer:\n",
    "            X_text = self.vectorizer.fit_transform(df[text_column])\n",
    "        else:\n",
    "            X_text = self.vectorizer.transform(df[text_column])\n",
    "        \n",
    "        X_keywords = keyword_counts.to_numpy()\n",
    "        X = hstack([X_text, csr_matrix(X_keywords)])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        keyword_present = np.any(X[:, -len(self.keyword_categories):].toarray(), axis=1)\n",
    "        X_train = X[keyword_present]\n",
    "        y_train = y[keyword_present]\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict_proba(self, text):\n",
    "        text = text.lower()\n",
    "        X_text_new = self.vectorizer.transform([text])\n",
    "        keyword_counts_new = np.array([[self.keyword_count(text, keywords) for keywords in self.keyword_categories.values()]])\n",
    "        negative_keyword_count_new = np.array([[self.keyword_count(text, self.negative_keywords)]])\n",
    "        \n",
    "        # Check if any keywords from keyword categories or general keywords are present\n",
    "        any_keyword_present = np.any(keyword_counts_new) or self.keyword_count(text, self.general_keywords) > 0\n",
    "        \n",
    "        if not any_keyword_present:\n",
    "            return 0.0\n",
    "        \n",
    "        X_new = hstack([X_text_new, csr_matrix(keyword_counts_new), csr_matrix(negative_keyword_count_new)])\n",
    "        \n",
    "        return self.model.predict_proba(X_new)[0, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of relevance for sample 1: 0.36\n",
      "Probability of relevance for sample 2: 0.36\n",
      "Probability of relevance for sample 3: 0.34\n",
      "Probability of relevance for sample 4: 0.36\n",
      "Probability of relevance for sample 5: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example DataFrame\n",
    "    training_data = {\n",
    "        'text': [\n",
    "            'This is the first document.', 'This document is the second document.', \n",
    "            'And this is the third one.', 'Is this the first document?',\n",
    "            'More text data.', 'Even more text.', 'Text data again.', \n",
    "            'And another one.', 'More examples.', 'Additional text.',\n",
    "            'Sample text.', 'Another sample.', 'More samples.', 'Final example.'\n",
    "        ],\n",
    "        'relevance': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0]  # Relevance labels\n",
    "    }\n",
    "    df_train = pd.DataFrame(training_data)\n",
    "    \n",
    "    # Define categories of keywords\n",
    "    keyword_categories = {\n",
    "        'Category1': ['first', 'second', 'third'],\n",
    "        'Category2': ['more', 'additional', 'sample']\n",
    "    }\n",
    "    \n",
    "    # Define general keywords\n",
    "    general_keywords = ['document', 'text']\n",
    "    \n",
    "    # Define negative keywords\n",
    "    negative_keywords = ['another', 'final']\n",
    "    \n",
    "    # Create an instance of the model\n",
    "    model = TextRelevanceModel(keyword_categories, general_keywords, negative_keywords)\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train = model.prepare_data(df_train, text_column='text')\n",
    "    y_train = df_train['relevance']\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(X_train, y_train)\n",
    "    \n",
    "    # Example DataFrame with 5 text samples\n",
    "    data = {\n",
    "        'text': [\n",
    "            'This is the first document.', \n",
    "            'This document is the second document.', \n",
    "            'And this is the third one.', \n",
    "            'Is this the first document?',\n",
    "            'More text data.'\n",
    "        ]\n",
    "    }\n",
    "    df_samples = pd.DataFrame(data)\n",
    "\n",
    "    # Predict the probability of relevance for each text sample\n",
    "    for i, text_sample in enumerate(df_samples['text']):\n",
    "        relevance_probability = model.predict_proba(text_sample)\n",
    "        print(f\"Probability of relevance for sample {i+1}: {relevance_probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand =614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.86       232\n",
      "           1       0.10      0.75      0.18         8\n",
      "\n",
      "    accuracy                           0.77       240\n",
      "   macro avg       0.54      0.76      0.52       240\n",
      "weighted avg       0.96      0.77      0.84       240\n",
      "\n",
      "Confusion Matrix:\n",
      " [[178  54]\n",
      " [  2   6]]\n",
      "Accuracy Score: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Using this on the actual dataset\n",
    "if __name__ == \"__main__\":\n",
    "    # Importing and dropping rows from Frame\n",
    "\n",
    "    df_coded = pd.read_csv('../data/processed_and_coded_posts.csv')\n",
    "    df = df_coded[['processed_text','highly_relevant']]\n",
    "    \n",
    "    #Importing keywords\n",
    "\n",
    "    csv_file_path = '../keywords/medications.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_med = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    medications = df_med.iloc[:, 0].tolist()\n",
    "\n",
    "    csv_file_path_2 = '../keywords/Treatment.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_therapy = pd.read_csv(csv_file_path_2)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    therapy = df_therapy.iloc[:, 0].tolist()\n",
    "\n",
    "    general_keywords = ['diagnose', 'diagnosed', 'dosage','dose', 'drug', 'drugs', 'harming', 'med', 'medication', 'medicine', 'medicines', 'meds', 'prescribe', 'prescribed', 'psychiatrist', 'psychiatrists', 'psychotherapy', 'recovery', 'session', 'therapist', 'therapists', 'therapy', 'treatment']\n",
    "\n",
    "    # Define categories of keywords\n",
    "    \n",
    "    keyword_categories = {\n",
    "    'medications': medications,\n",
    "    'therapy': therapy\n",
    "}\n",
    "    \n",
    "    # Define negative keywords\n",
    "    negative_keywords = ['relationship', 'friend', 'fp', 'partner', 'dating']\n",
    "    \n",
    "    # Create an instance of the model\n",
    "    model = TextRelevanceModel(keyword_categories, general_keywords, negative_keywords)\n",
    "    model2 = TextRelevanceModel(keyword_categories, general_keywords, negative_keywords,AdaBoostClassifier())\n",
    "\n",
    "    # Test train split the data\n",
    "    df_train, df_test = train_test_split(df, test_size=0.4, stratify=df['highly_relevant'], random_state=rand)\n",
    "\n",
    "     # Prepare and train the model\n",
    "    X_train = model.prepare_data(df_train, text_column='processed_text', fit_vectorizer=True)\n",
    "    y_train = df_train['highly_relevant']\n",
    "    model.train(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Prepare the test data\n",
    "    X_test = model.prepare_data(df_test, text_column='processed_text', fit_vectorizer=False)\n",
    "    y_test = df_test['highly_relevant']\n",
    "    \n",
    "    # Predict the probability of relevance for each text sample in the test set\n",
    "    y_pred_proba = []\n",
    "    for text_sample in df_test['processed_text']:\n",
    "        relevance_probability = model.predict_proba(text_sample)\n",
    "        y_pred_proba.append(relevance_probability)\n",
    "    \n",
    "    \n",
    "    # Convert probabilities to binary predictions using a threshold (e.g., 0.05)\n",
    "    threshold = 0.05\n",
    "    y_pred = [1 if prob >= threshold else 0 for prob in y_pred_proba]\n",
    "\n",
    "   # Evaluate the model performance\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.84       232\n",
      "           1       0.09      0.75      0.16         8\n",
      "\n",
      "    accuracy                           0.74       240\n",
      "   macro avg       0.54      0.74      0.50       240\n",
      "weighted avg       0.96      0.74      0.82       240\n",
      "\n",
      "Confusion Matrix:\n",
      " [[171  61]\n",
      " [  2   6]]\n",
      "Accuracy Score: 0.7375\n"
     ]
    }
   ],
   "source": [
    "model = TextRelevanceModel(keyword_categories, general_keywords, negative_keywords,AdaBoostClassifier())\n",
    "\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Test train split the data\n",
    "df_train, df_test = train_test_split(df, test_size=0.4, stratify=df['highly_relevant'], random_state=rand)\n",
    "\n",
    "    # Prepare and train the model\n",
    "X_train = model.prepare_data(df_train, text_column='processed_text', fit_vectorizer=True)\n",
    "y_train = df_train['highly_relevant']\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = model.prepare_data(df_test, text_column='processed_text', fit_vectorizer=False)\n",
    "y_test = df_test['highly_relevant']\n",
    "\n",
    "# Predict the probability of relevance for each text sample in the test set\n",
    "y_pred_proba = []\n",
    "for text_sample in df_test['processed_text']:\n",
    "    relevance_probability = model.predict_proba(text_sample)\n",
    "    y_pred_proba.append(relevance_probability)\n",
    "\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.05)\n",
    "threshold = 0.2\n",
    "y_pred = [1 if prob >= threshold else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       232\n",
      "           1       0.15      0.75      0.25         8\n",
      "\n",
      "    accuracy                           0.85       240\n",
      "   macro avg       0.57      0.80      0.58       240\n",
      "weighted avg       0.96      0.85      0.89       240\n",
      "\n",
      "Confusion Matrix:\n",
      " [[198  34]\n",
      " [  2   6]]\n",
      "Accuracy Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "keyword_categories = {\n",
    "    'medications': medications,\n",
    "    'therapy': therapy,\n",
    "    'general': general_keywords\n",
    "}\n",
    "\n",
    "general_keywords_2 = []\n",
    "\n",
    "model = TextRelevanceModel(keyword_categories,general_keywords_2,negative_keywords)\n",
    "\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Test train split the data\n",
    "df_train, df_test = train_test_split(df, test_size=0.4, stratify=df['highly_relevant'], random_state=rand)\n",
    "\n",
    "    # Prepare and train the model\n",
    "X_train = model.prepare_data(df_train, text_column='processed_text', fit_vectorizer=True)\n",
    "y_train = df_train['highly_relevant']\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = model.prepare_data(df_test, text_column='processed_text', fit_vectorizer=False)\n",
    "y_test = df_test['highly_relevant']\n",
    "\n",
    "# Predict the probability of relevance for each text sample in the test set\n",
    "y_pred_proba = []\n",
    "for text_sample in df_test['processed_text']:\n",
    "    relevance_probability = model.predict_proba(text_sample)\n",
    "    y_pred_proba.append(relevance_probability)\n",
    "\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.05)\n",
    "threshold = 0.05\n",
    "y_pred = [1 if prob >= threshold else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       232\n",
      "           1       0.23      0.88      0.37         8\n",
      "\n",
      "    accuracy                           0.90       240\n",
      "   macro avg       0.61      0.89      0.66       240\n",
      "weighted avg       0.97      0.90      0.93       240\n",
      "\n",
      "Confusion Matrix:\n",
      " [[209  23]\n",
      " [  1   7]]\n",
      "Accuracy Score: 0.9\n"
     ]
    }
   ],
   "source": [
    "keyword_categories = {\n",
    "    'medications': medications,\n",
    "    'therapy': therapy,\n",
    "    'general': general_keywords\n",
    "}\n",
    "\n",
    "general_keywords_blank = []\n",
    "negative_keywords_blank = []\n",
    "\n",
    "model = TextRelevanceModel(keyword_categories,general_keywords_blank,negative_keywords_blank)\n",
    "\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Test train split the data\n",
    "df_train, df_test = train_test_split(df, test_size=0.4, stratify=df['highly_relevant'], random_state=rand)\n",
    "\n",
    "    # Prepare and train the model\n",
    "X_train = model.prepare_data(df_train, text_column='processed_text', fit_vectorizer=True)\n",
    "y_train = df_train['highly_relevant']\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = model.prepare_data(df_test, text_column='processed_text', fit_vectorizer=False)\n",
    "y_test = df_test['highly_relevant']\n",
    "\n",
    "# Predict the probability of relevance for each text sample in the test set\n",
    "y_pred_proba = []\n",
    "for text_sample in df_test['processed_text']:\n",
    "    relevance_probability = model.predict_proba(text_sample)\n",
    "    y_pred_proba.append(relevance_probability)\n",
    "\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.05)\n",
    "threshold = 0.05\n",
    "y_pred = [1 if prob >= threshold else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fairly large number of settings, this model seems to be doing the best. Here, we don't include any 'negative keywords' and just count the number of keywords in each category. In particular, there is no 'general keyword' category which isn't counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/gkhan/Library/Python/3.12/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       232\n",
      "           1       0.17      0.75      0.28         8\n",
      "\n",
      "    accuracy                           0.87       240\n",
      "   macro avg       0.58      0.81      0.60       240\n",
      "weighted avg       0.96      0.87      0.91       240\n",
      "\n",
      "Confusion Matrix:\n",
      " [[203  29]\n",
      " [  2   6]]\n",
      "Accuracy Score: 0.8708333333333333\n"
     ]
    }
   ],
   "source": [
    "keyword_categories = {\n",
    "    'medications': medications,\n",
    "    'therapy': therapy,\n",
    "    'general': general_keywords\n",
    "}\n",
    "\n",
    "\n",
    "model = TextRelevanceModel(keyword_categories,general_keywords_blank,negative_keywords_blank,AdaBoostClassifier())\n",
    "\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Test train split the data\n",
    "df_train, df_test = train_test_split(df, test_size=0.4, stratify=df['highly_relevant'], random_state=rand)\n",
    "\n",
    "    # Prepare and train the model\n",
    "X_train = model.prepare_data(df_train, text_column='processed_text', fit_vectorizer=True)\n",
    "y_train = df_train['highly_relevant']\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "\n",
    "# Prepare the test data\n",
    "X_test = model.prepare_data(df_test, text_column='processed_text', fit_vectorizer=False)\n",
    "y_test = df_test['highly_relevant']\n",
    "\n",
    "# Predict the probability of relevance for each text sample in the test set\n",
    "y_pred_proba = []\n",
    "for text_sample in df_test['processed_text']:\n",
    "    relevance_probability = model.predict_proba(text_sample)\n",
    "    y_pred_proba.append(relevance_probability)\n",
    "\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.05)\n",
    "threshold = 0.3\n",
    "y_pred = [1 if prob >= threshold else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
