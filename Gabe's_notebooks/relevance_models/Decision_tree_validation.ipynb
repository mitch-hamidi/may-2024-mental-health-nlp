{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the relevance model on the manually coded comments\n",
    "\n",
    "As a final step, we run the relevance model on the testing set coded by Eunbin. Right now, this only contains relevant comments, so we can only assess the recall of the model, not the precision. We will have to enlarge the testing set with the irrelevant comments to assess performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the manually coded relevant comments\n",
    "\n",
    "df1=pd.read_csv('../../esk_working/val_df.csv')\n",
    "df1=df1.dropna(how='any')\n",
    "# Dropping the data points with null values \n",
    "df1 = df1.dropna(how = 'any', axis = 0)\n",
    "# lowercasing the column names so it will be easier for access ^^\n",
    "df1.columns = df1.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>post</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’ve been in and out of therapy (mostly in) fo...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Been in regular (twice a week) therapy for ove...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In therapy since I was 14. It's been over 20 y...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tried CBT for years, and never got anywhere. \\...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment               author  \\\n",
       "0  I’ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1  i’ve been in and out of therapy (mostly in) fo...          oddthing757   \n",
       "2  Been in regular (twice a week) therapy for ove...         bedrock_BEWD   \n",
       "3  In therapy since I was 14. It's been over 20 y...  Own_Collection_8916   \n",
       "4  Tried CBT for years, and never got anywhere. \\...       sky-amethyst23   \n",
       "\n",
       "      post  relevance  \n",
       "0  1bmk9m2          1  \n",
       "1  1bmk9m2          1  \n",
       "2  1bmk9m2          1  \n",
       "3  1bmk9m2          1  \n",
       "4  1bmk9m2          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Changing to Lower Case\n",
    "df1['comment'] = df1['comment'].str.lower()\n",
    "\n",
    "# Step 2: Replacing the Repeating Pattern of '&#039;'\n",
    "df1['comment'] = df1['comment'].str.replace(\"&#039;\", \"\")\n",
    "\n",
    "# Step 3: Removing All Special Characters\n",
    "df1['comment'] = df1['comment'].str.replace(r'[^\\w\\d\\s]', '')\n",
    "\n",
    "# Step 4: Removing Leading and Trailing Whitespaces\n",
    "df1['comment'] = df1['comment'].str.strip()\n",
    "\n",
    "# Step 5: Replacing Multiple Spaces with Single Space\n",
    "df1['comment'] = df1['comment'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               comment            author  \\\n",
      "71   >i don't currently go to therapy,\\n\\nunfortuna...  Throwawayabc2345   \n",
      "282  its a no for me, none of them really helped.\\n...         trikkiirl   \n",
      "\n",
      "        post  relevance  \n",
      "71   12pyiln          1  \n",
      "282  14s0tfr          1  \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'selftext' is one of the columns you expect in df1\n",
    "# You should check the actual columns in your DataFrame\n",
    "# Make sure to load your DataFrame properly before running these operations\n",
    "\n",
    "# Check if 'selftext' is in the columns\n",
    "if 'comment' in df1.columns:\n",
    "    # Drop rows where 'selftext' is '[removed]' or '\\[removed\\]'\n",
    "    df1.drop(df1[(df1['comment'] =='\\\\[removed\\\\]')].index, inplace=True)\n",
    "    df1.drop(df1[(df1['comment'] =='[removed]')].index, inplace=True)\n",
    "\n",
    "    df1.drop(df1[(df1['comment'] =='\\\\[deleted\\\\]')].index, inplace=True)\n",
    "    df1.drop(df1[(df1['comment'] =='[deleted]')].index, inplace=True)\n",
    "\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df1.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    # Randomly sample 2 rows\n",
    "    print(df1.sample(2))\n",
    "else:\n",
    "    print(\"'selftext' column not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Punctuation removal\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = remove_punctuation(text).split()\n",
    "    \n",
    "    # Lowercase and remove stopwords\n",
    "    tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the combined text column\n",
    "df1['processed_comment'] = df1['comment'].apply(preprocess_text)\n",
    "df1['processed_comment'] = df1['processed_comment'].apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and training the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "class TextRelevanceModel:\n",
    "    def __init__(self, keyword_categories, negative_keywords=None, model=None):\n",
    "        self.keyword_categories = keyword_categories\n",
    "        self.negative_keywords = negative_keywords if negative_keywords is not None else []\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = model if model is not None else LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    def keyword_count(self, text, keywords):\n",
    "        return sum(1 for word in text.lower().split() if word in keywords)\n",
    "    \n",
    "    def prepare_data(self, df, text_column):\n",
    "        df[text_column] = df[text_column].str.lower()\n",
    "\n",
    "        keyword_counts = pd.DataFrame()\n",
    "        \n",
    "        for category, keywords in self.keyword_categories.items():\n",
    "            keyword_counts[category + '_count'] = df[text_column].apply(lambda x: self.keyword_count(x, keywords))\n",
    "        \n",
    "        keyword_counts['negative_keyword_count'] = df[text_column].apply(lambda x: self.keyword_count(x, self.negative_keywords))\n",
    "        \n",
    "        X_text = self.vectorizer.fit_transform(df[text_column])\n",
    "        X_keywords = keyword_counts.to_numpy()\n",
    "        X = hstack([X_text, csr_matrix(X_keywords)])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        keyword_present = np.any(X[:, -len(self.keyword_categories):].toarray(), axis=1)\n",
    "        X_train = X[keyword_present]\n",
    "        y_train = y[keyword_present]\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict_proba(self, text):\n",
    "        X_text_new = self.vectorizer.transform([text])\n",
    "        keyword_counts_new = np.array([[self.keyword_count(text, keywords) for keywords in self.keyword_categories.values()]])\n",
    "        negative_keyword_count_new = np.array([[self.keyword_count(text, self.negative_keywords)]])\n",
    "        X_new = hstack([X_text_new, csr_matrix(keyword_counts_new), csr_matrix(negative_keyword_count_new)])\n",
    "        \n",
    "        if not np.any(keyword_counts_new):\n",
    "            return 0.0\n",
    "        \n",
    "        return self.model.predict_proba(X_new)[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9j/j4gyltgs6txd83bg66_mv4fn664jzt/T/ipykernel_66684/3456766118.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[text_column] = df[text_column].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Importing and dropping rows from Frame\n",
    "\n",
    "    df_coded = pd.read_csv('../data/processed_and_coded_posts.csv')\n",
    "    df2 = df_coded[['processed_text','highly_relevant']]\n",
    "    \n",
    "    #Importing keywords\n",
    "\n",
    "    csv_file_path = '../keywords/medications.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_med = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    medications = df_med.iloc[:, 0].tolist()\n",
    "\n",
    "    csv_file_path_2 = '../keywords/Treatment.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_therapy = pd.read_csv(csv_file_path_2)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    therapy = df_therapy.iloc[:, 0].tolist()\n",
    "\n",
    "    general_keywords = ['diagnose', 'diagnosed', 'dosage','dose', 'drug', 'drugs', 'harming', 'med', 'medication', 'medicine', 'medicines', 'meds', 'prescribe', 'prescribed', 'psychiatrist', 'psychiatrists', 'psychotherapy', 'recovery', 'session', 'therapist', 'therapists', 'therapy', 'treatment']\n",
    "\n",
    "    # Define categories of keywords\n",
    "    \n",
    "    keyword_categories = {\n",
    "    'general_keywords': general_keywords,\n",
    "    'medications': medications,\n",
    "    'therapy': therapy\n",
    "}\n",
    "    \n",
    "    # Define negative keywords\n",
    "    #negative_keywords = ['relationship', 'friend', 'together', 'fp', 'people', 'person', 'partner', 'dating']\n",
    "    negative_keywords_2 = []\n",
    "\n",
    "\n",
    "    # Create an instance of the model\n",
    "    model = TextRelevanceModel(keyword_categories,negative_keywords_2)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #Prepare data\n",
    "    X = model.prepare_data(df2, text_column='processed_text')\n",
    "    y = df2['highly_relevant']\n",
    "\n",
    "    # Train the model\n",
    "    model.train(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model on the manually coded dataset\n",
    "\n",
    "Here, I use .1 as a threshold because that is what was done in the previous evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['relevance_probability']=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14374214917702083"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making sure the code is working\n",
    "model.predict_proba('This is a random string with dbt in it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>post</th>\n",
       "      <th>relevance</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>relevance_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i’ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>i’ve seeing therapist since age 25 i’m 47 i’ve...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’ve been in and out of therapy (mostly in) fo...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>i’ve therapy mostly past 10ish year helpful ha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>been in regular (twice a week) therapy for ove...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>regular twice week therapy ten year started ad...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in therapy since i was 14. it's been over 20 y...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>therapy since 14 20 year ive learned lot year ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried cbt for years, and never got anywhere. \\...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>tried cbt year never got anywhere dbt iop save...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment               author  \\\n",
       "0  i’ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1  i’ve been in and out of therapy (mostly in) fo...          oddthing757   \n",
       "2  been in regular (twice a week) therapy for ove...         bedrock_BEWD   \n",
       "3  in therapy since i was 14. it's been over 20 y...  Own_Collection_8916   \n",
       "4  tried cbt for years, and never got anywhere. \\...       sky-amethyst23   \n",
       "\n",
       "      post  relevance                                  processed_comment  \\\n",
       "0  1bmk9m2          1  i’ve seeing therapist since age 25 i’m 47 i’ve...   \n",
       "1  1bmk9m2          1  i’ve therapy mostly past 10ish year helpful ha...   \n",
       "2  1bmk9m2          1  regular twice week therapy ten year started ad...   \n",
       "3  1bmk9m2          1  therapy since 14 20 year ive learned lot year ...   \n",
       "4  1bmk9m2          1  tried cbt year never got anywhere dbt iop save...   \n",
       "\n",
       "   relevance_probability  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the relevance probability for a given text\n",
    "def get_relevance_probability(text):\n",
    "    return model.predict_proba(text)\n",
    "\n",
    "# Apply the function to each row in the 'processed_text' column and create the new column\n",
    "df1['relevance_probability'] = df1['processed_comment'].apply(get_relevance_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[df1['relevance_probability']>.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 294 entries, 0 to 310\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   comment                294 non-null    object \n",
      " 1   author                 294 non-null    object \n",
      " 2   post                   294 non-null    object \n",
      " 3   relevance              294 non-null    int64  \n",
      " 4   processed_comment      294 non-null    object \n",
      " 5   relevance_probability  294 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 16.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has length 294, which means that the model thought that 294 out of the original 311 comments were relevant. Therefore, we have a recall of 95%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
