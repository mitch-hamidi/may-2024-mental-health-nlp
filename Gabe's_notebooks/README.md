This folder contains Gabe Khan's work on the mental health nlp project for the May 2024 cohort of the Erdos Institute.

Goals:
    1. Clean and perform exploratory data analysis with the Kaggle dataset containing Reddit posts from r/bpd from 2012 through 2022.
    2. Build a model to classify posts which are relevant to the treatment and medical management of r/bpd. One considerable challenge is that the vast majority of posts (~95%) are not relevant, so the data is very imbalanced.
    3. After a model for determining relevancy was built, find the most relevant posts in r/bpd and analyze these posts. For this, I used an NER (found by Emilie Curl) to classify all the medications in the post. For posts containing a particular medication, I ran a script to determine the sentiment towards that medication. I did not try to build my own sentiment analysis model but instead used prompt engineering with GPT-4o.


Conclusions:
    The chosen relevancy model can be used to quickly return a collection of highly-relevance posts, with extremely good precision once the threshold is sufficiently large (e.g., .3 or .5). At these values, the recall is fairly small, but since we have a large number of posts, this still yields a high quality dataset. Further investigation is needed to determine whether these posts are representative of relevant posts. The dataset containing posts with threshold over .5 and all the medication in each post can be found in /data/highly_relevant_posts_descending_threshold_50_augmented.csv.

     Due to time constraints and how difficult it is to determine sentiments towards a single aspect within a body of text, I was not able to design my own sentiment analysis model. However, the high-quality dataset was small enough to use GPT-4o and prompt engineering to generate these sentiments. For the most part, this analysis was highly accurate in determining positive or negative sentiments, although it did struggle to distinguish between cases where the sentiment was mixed and those where the user did not provide background on the medication. From manual coding and comparison to the generated responses, the sentiment analysis was 76% accurate but 88.5% accurate in determining positive, negative and others. From validation, we found that the model tended to be a slightly optimistic and to see this we can compare the raw Lamotrigine sentiments with the ones that were manually corrected.

     We ran the code for the three most frequently referenced medications, which were Lamotrigine (aka Lamictal), Sertraline (aka Zoloft) and Quetiapine (aka Seroquel) to get sentiment breakdowns.

        1. Lamotrigine (raw scores) : - 196 positive (35.5%), 88 negative (16%),  268 unclear/mixed/not taken (48.5%)
        2. Lamtrogine (200 manually corrected scores): 60 positive (30%), 35 negative (17.5%), 105 unclear/mixed/not taken (52.5%)
        2. Sertraline: 107 positive (26%), 121 negative (30%), 178 unclear/mixed/not taken (44%)
        3. Quetiapine: 118 positive (30%), 83 negative (21%), 195 unclear/mixed/not taken (49%)



Folder contents:

1_Initial_analysis_and_cleaning contains the initial cleaning of the data and some preliminary data analysis. At this point, a sample of posts were separated from the dataset for manual coding for relevance.

2_Analysis_of_manually_coded_data contains some preliminary analysis of the manual coded data, including trying to understand its breakdown and the performance of simple models to classify relevant. After this point, I started trying to build models with improved performance.

'data' contains all the relevant data and csv files generated by our analysis. I have not attempted to organize it in any way.

'keywords' contains several files listing keywords for the treatment and diagnosis of bpd, as well as code used to generate them. These are also not organized, and mostly just used as parameters in the model

'relevance_models' contains the main statistical analysis in this project. Here, I attempted to model which posts were relevant to the treatment of bpd. From manual coding, only about 5% of posts were relevant, so this dataset is quite noisy. Five classes of models were considered and a final version was decided on and validated.

'relevant_post_analysis' starts by taking the chosen statistical model and running it on a large portion of the Kaggle dataset (r/bpd posts from 1-1-2014 through 1-1-2022). With a threshold of .5, this yielded 2557 highly relevant posts, nearly all of which discuss the medical management of bpd in some form. We also used a named entity recognition (NER) for all the medications in these posts. 


Since running the sentiment analysis required API calls to OpenAI, doing so was not free. Therefore, a lot of effort was put into prompt engineering to ensure that all calls to the server would return useful responses. Processing the most frequently mentioned medication (Lamotrigine) cost $1.80 and the second most frequently mentioned medication (Sertraline) cost $1.56. However, doing so yielded detailed breakdown of the sentiments about these medications.

Notes:
1. Files in folders are numbered to explain their order.
2. 'keywords', 'relevancy_models' and 'relevant_post_analysis' contain Readme files with more details on their contents. 