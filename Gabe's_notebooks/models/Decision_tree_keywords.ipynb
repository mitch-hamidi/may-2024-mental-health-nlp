{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial decision tree model\n",
    "\n",
    "There is nothing wrong with this model, but I wanted to add a few more features to the class for ease of use. I would recommend using the 'Decision_tree_model_in_one' model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probability for the sample text: 0.5922116401377012\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRelevanceModel:\n",
    "    def __init__(self, keyword_categories, negative_keywords=None, model=None):\n",
    "        \"\"\"\n",
    "        Initialize the model with keyword categories and an optional model.\n",
    "        \n",
    "        :param keyword_categories: Dictionary where keys are category names and values are lists of keywords.\n",
    "        :param negative_keywords: List of negative keywords.\n",
    "        :param model: An optional machine learning model. Defaults to LogisticRegression.\n",
    "        \"\"\"\n",
    "        self.keyword_categories = keyword_categories\n",
    "        self.negative_keywords = negative_keywords if negative_keywords is not None else []\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = model if model is not None else LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    def keyword_count(self, text, keywords):\n",
    "        \"\"\"Count the number of keywords present in the text.\"\"\"\n",
    "        return sum(1 for word in text.lower().split() if word in keywords)\n",
    "    \n",
    "    def prepare_data(self, df, text_column, target_column):\n",
    "        \"\"\"Prepare features and target variable from the dataframe.\"\"\"\n",
    "        # Initialize a DataFrame to store keyword counts for each category\n",
    "        keyword_counts = pd.DataFrame()\n",
    "        \n",
    "        for category, keywords in self.keyword_categories.items():\n",
    "            keyword_counts[category + '_count'] = df[text_column].apply(lambda x: self.keyword_count(x, keywords))\n",
    "        \n",
    "        # Calculate negative keyword counts\n",
    "        keyword_counts['negative_keyword_count'] = df[text_column].apply(lambda x: self.keyword_count(x, self.negative_keywords))\n",
    "        \n",
    "        # Vectorize the text data\n",
    "        X_text = self.vectorizer.fit_transform(df[text_column])\n",
    "        \n",
    "        # Combine the text features and the keyword count features\n",
    "        X_keywords = keyword_counts.to_numpy()\n",
    "        X = hstack([X_text, csr_matrix(X_keywords)])\n",
    "        \n",
    "        # Target variable\n",
    "        y = df[target_column]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train(self, df, text_column, target_column):\n",
    "        \"\"\"Train the model using the provided dataframe.\"\"\"\n",
    "        X, y = self.prepare_data(df, text_column, target_column)\n",
    "        \n",
    "        # Convert X to csr_matrix for slicing\n",
    "        X = csr_matrix(X)\n",
    "        \n",
    "        # Filter out rows where no keywords are present in any category\n",
    "        keyword_present = np.any(X[:, -len(self.keyword_categories):].toarray(), axis=1)\n",
    "        X = X[keyword_present]\n",
    "        y = y[keyword_present]\n",
    "        \n",
    "        # Fit the model on the filtered data\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"Predict the relevance of a new text.\"\"\"\n",
    "        # Vectorize the input text\n",
    "        X_text_new = self.vectorizer.transform([text])\n",
    "        \n",
    "        # Calculate keyword counts for the new text\n",
    "        keyword_counts_new = np.array([[self.keyword_count(text, keywords) for keywords in self.keyword_categories.values()]])\n",
    "        negative_keyword_count_new = np.array([[self.keyword_count(text, self.negative_keywords)]])\n",
    "        \n",
    "        # Combine features\n",
    "        X_new = hstack([X_text_new, csr_matrix(keyword_counts_new), csr_matrix(negative_keyword_count_new)])\n",
    "        \n",
    "        # Check if any keyword from the categories is present\n",
    "        if not np.any(keyword_counts_new):\n",
    "            return 0.0\n",
    "        \n",
    "        # Predict using the model\n",
    "        return self.model.predict_proba(X_new)[0, 1]  # Return the probability of the positive class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Importing and dropping rows from ataFrame\n",
    "\n",
    "    df_coded = pd.read_csv('../data/processed_and_coded_posts.csv')\n",
    "    df = df_coded[['processed_text','highly_relevant']]\n",
    "    \n",
    "    #Importing keywords\n",
    "\n",
    "    csv_file_path = '../keywords/medications.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_med = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    medications = df_med.iloc[:, 0].tolist()\n",
    "\n",
    "    csv_file_path_2 = '../keywords/Treatment.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_therapy = pd.read_csv(csv_file_path_2)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    therapy = df_therapy.iloc[:, 0].tolist()\n",
    "\n",
    "    general_keywords = ['medicine','therapy','treatment','recovery','prescribed','diagnosed','med','meds','prescribe','therapist','session','psychiatrist','psychiatrists','dosage','medication', 'dbt', 'abilify', 'outpatient', 'therapist', 'harming','medicine','therapy','treatment','recovery','prescribed','diagnosed','therapists','prescribe','diagnose','medicines','drugs','drug','therapist','session']\n",
    "\n",
    "    # Define categories of keywords\n",
    "    \n",
    "    keyword_categories = {\n",
    "    'general_keywords': general_keywords,\n",
    "    'medications': medications,\n",
    "    'therapy': therapy\n",
    "}\n",
    "    \n",
    "    # Define negative keywords\n",
    "    negative_keywords = ['relationship', 'friend', 'together', 'fp', 'people', 'person', 'partner', 'dating']\n",
    "    \n",
    "    # Create an instance of the model\n",
    "    model = TextRelevanceModel(keyword_categories, negative_keywords)\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=17, stratify=df.highly_relevant)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.train(df_train, text_column='processed_text', target_column='highly_relevant')\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
