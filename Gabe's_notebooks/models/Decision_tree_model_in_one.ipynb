{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree model\n",
    "\n",
    "This model uses a keyword search to determine if posts contain a keyword. If not, it marks them as irrelevant. If they do contain a keyword, it performs logistic regression to determine relevance. To improve performance, it also takes various lists of keywords (such as medications, therapies, etc) and a list of negative keywords which are negatively associated with relevance (e.g. 'dating', 'fp'). These negative keywords were determined by the baseline model, but can easily be altered to improve (or worsen) model performance. In addition, there is a parameter called threshold which determines the probability needed to mark a post as relevant or not. Right now, it is set to .1 (although it might be better to make it even smaller). Feel free to alter the keywords.\n",
    "\n",
    "Right now, the model incorporates the test train split within the model, and at some point I'll try to remove that without breaking everything, but my initial attempts to do so did not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class TextRelevanceModel:\n",
    "    def __init__(self, keyword_categories, negative_keywords=None, model=None):\n",
    "        \"\"\"\n",
    "        Initialize the model with keyword categories and an optional model.\n",
    "        \n",
    "        :param keyword_categories: Dictionary where keys are category names and values are lists of keywords.\n",
    "        :param negative_keywords: List of negative keywords.\n",
    "        :param model: An optional machine learning model. Defaults to LogisticRegression.\n",
    "        \"\"\"\n",
    "        self.keyword_categories = keyword_categories\n",
    "        self.negative_keywords = negative_keywords if negative_keywords is not None else []\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = model if model is not None else LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    def keyword_count(self, text, keywords):\n",
    "        \"\"\"Count the number of keywords present in the text.\"\"\"\n",
    "        return sum(1 for word in text.lower().split() if word in keywords)\n",
    "    \n",
    "    def prepare_data(self, df, text_column, target_column):\n",
    "        \"\"\"Prepare features and target variable from the dataframe.\"\"\"\n",
    "        # Initialize a DataFrame to store keyword counts for each category\n",
    "        keyword_counts = pd.DataFrame()\n",
    "        \n",
    "        for category, keywords in self.keyword_categories.items():\n",
    "            keyword_counts[category + '_count'] = df[text_column].apply(lambda x: self.keyword_count(x, keywords))\n",
    "        \n",
    "        # Calculate negative keyword counts\n",
    "        keyword_counts['negative_keyword_count'] = df[text_column].apply(lambda x: self.keyword_count(x, self.negative_keywords))\n",
    "        \n",
    "        # Vectorize the text data\n",
    "        X_text = self.vectorizer.fit_transform(df[text_column])\n",
    "        \n",
    "        # Combine the text features and the keyword count features\n",
    "        X_keywords = keyword_counts.to_numpy()\n",
    "        X = hstack([X_text, csr_matrix(X_keywords)])\n",
    "        \n",
    "        # Target variable\n",
    "        y = df[target_column]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the model using the provided features and target variable.\"\"\"\n",
    "        # Filter out rows where no keywords are present in any category\n",
    "        keyword_present = np.any(X[:, -len(self.keyword_categories):].toarray(), axis=1)\n",
    "        X_train = X[keyword_present]\n",
    "        y_train = y[keyword_present]\n",
    "        \n",
    "        # Fit the model on the filtered data\n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict_proba(self, text):\n",
    "        \"\"\"Predict the probability of relevance for a new text.\"\"\"\n",
    "        # Vectorize the input text\n",
    "        X_text_new = self.vectorizer.transform([text])\n",
    "        \n",
    "        # Calculate keyword counts for the new text\n",
    "        keyword_counts_new = np.array([[self.keyword_count(text, keywords) for keywords in self.keyword_categories.values()]])\n",
    "        negative_keyword_count_new = np.array([[self.keyword_count(text, self.negative_keywords)]])\n",
    "        \n",
    "        # Combine features\n",
    "        X_new = hstack([X_text_new, csr_matrix(keyword_counts_new), csr_matrix(negative_keyword_count_new)])\n",
    "        \n",
    "        # Check if any keyword from the categories is present\n",
    "        if not np.any(keyword_counts_new):\n",
    "            return 0.0\n",
    "        \n",
    "        # Predict using the model\n",
    "        return self.model.predict_proba(X_new)[0, 1]  # Return the probability of the positive class\n",
    "    \n",
    "    def evaluate(self, df, text_column, target_column, threshold=0.5):\n",
    "        \"\"\"Evaluate the model performance on the provided dataframe.\"\"\"\n",
    "        X, y = self.prepare_data(df, text_column, target_column)\n",
    "        \n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        \n",
    "        # Train the model on the training set\n",
    "        self.train(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities on the test set\n",
    "        y_proba = np.array([self.predict_proba(text) for text in df[text_column].iloc[y_test.index]])\n",
    "        \n",
    "        # Apply the threshold to get the predicted classes\n",
    "        y_pred = (y_proba >= threshold).astype(int)\n",
    "        \n",
    "        # Print the classification report\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Print the confusion matrix\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       116\n",
      "           1       0.40      1.00      0.57         4\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.70      0.97      0.77       120\n",
      "weighted avg       0.98      0.95      0.96       120\n",
      "\n",
      "[[110   6]\n",
      " [  0   4]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Importing and dropping rows from ataFrame\n",
    "\n",
    "    df_coded = pd.read_csv('../data/processed_and_coded_posts.csv')\n",
    "    df = df_coded[['processed_text','highly_relevant']]\n",
    "    \n",
    "    #Importing keywords\n",
    "\n",
    "    csv_file_path = '../keywords/medications.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_med = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    medications = df_med.iloc[:, 0].tolist()\n",
    "\n",
    "    csv_file_path_2 = '../keywords/Treatment.csv'\n",
    "\n",
    "    # Read the CSV file\n",
    "    df_therapy = pd.read_csv(csv_file_path_2)\n",
    "\n",
    "    # Extract the first column as a list of keywords\n",
    "    therapy = df_therapy.iloc[:, 0].tolist()\n",
    "\n",
    "    general_keywords = ['medicine','therapy','treatment','recovery','prescribed','diagnosed','med','meds','prescribe','therapist','session','psychiatrist','psychiatrists','dosage','medication', 'dbt', 'abilify', 'outpatient', 'therapist', 'harming','medicine','therapy','treatment','recovery','prescribed','diagnosed','therapists','prescribe','diagnose','medicines','drugs','drug','therapist','session']\n",
    "\n",
    "    # Define categories of keywords\n",
    "    \n",
    "    keyword_categories = {\n",
    "    'general_keywords': general_keywords,\n",
    "    'medications': medications,\n",
    "    'therapy': therapy\n",
    "    }\n",
    "    \n",
    "    # Define negative keywords\n",
    "    negative_keywords = ['relationship', 'friend', 'together', 'fp', 'people', 'person', 'partner', 'dating']\n",
    "    \n",
    "    \n",
    "\n",
    " # Create an instance of the model\n",
    "    model = TextRelevanceModel(keyword_categories, negative_keywords)\n",
    "    \n",
    "    # Evaluate the model on the DataFrame with a specified threshold to increase sensitivity\n",
    "    model.evaluate(df, text_column='processed_text', target_column='highly_relevant', threshold=0.1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
