{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347b07d6-e190-42df-add2-460f298d6842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import the necessary libraries and modules\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d14234-410c-4f1a-bea6-a2b9521f55a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Post</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’ve been in and out of therapy (mostly in) fo...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Been in regular (twice a week) therapy for ove...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In therapy since I was 14. It's been over 20 y...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tried CBT for years, and never got anywhere. \\...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>I'm on 20mg abilify and 400mg epilim. I've bee...</td>\n",
       "      <td>formobymo</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>I was prescribed Lamictal once and had a sever...</td>\n",
       "      <td>Doanya</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>300mg quetiapine and 40mg fluoxetine.\\n\\nI use...</td>\n",
       "      <td>Ddog1909</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>I was on zoloft for several years in my early ...</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>I took Lamictal and Lithium and I hated both.</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment               Author  \\\n",
       "0    I’ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1    i’ve been in and out of therapy (mostly in) fo...          oddthing757   \n",
       "2    Been in regular (twice a week) therapy for ove...         bedrock_BEWD   \n",
       "3    In therapy since I was 14. It's been over 20 y...  Own_Collection_8916   \n",
       "4    Tried CBT for years, and never got anywhere. \\...       sky-amethyst23   \n",
       "..                                                 ...                  ...   \n",
       "306  I'm on 20mg abilify and 400mg epilim. I've bee...            formobymo   \n",
       "307  I was prescribed Lamictal once and had a sever...               Doanya   \n",
       "308  300mg quetiapine and 40mg fluoxetine.\\n\\nI use...             Ddog1909   \n",
       "309  I was on zoloft for several years in my early ...           KronikHaze   \n",
       "310      I took Lamictal and Lithium and I hated both.           KronikHaze   \n",
       "\n",
       "        Post  relevance  \n",
       "0    1bmk9m2          1  \n",
       "1    1bmk9m2          1  \n",
       "2    1bmk9m2          1  \n",
       "3    1bmk9m2          1  \n",
       "4    1bmk9m2          1  \n",
       "..       ...        ...  \n",
       "306   w5q5qv          1  \n",
       "307   w5q5qv          1  \n",
       "308   w5q5qv          1  \n",
       "309   w5q5qv          1  \n",
       "310   w5q5qv          1  \n",
       "\n",
       "[311 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import a csv file containing comments scraped from reddit as a data frame\n",
    "val_df = pd.read_csv(\"C:/Users/ESK/Documents/DataScience/working/project-mh/val_df.csv\")\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08c7f39-e2b2-4e36-8085-565e1ab36c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ESK\\AppData\\Local\\Temp\\ipykernel_3348\\358633829.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  val_df[\"Comment\"].fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "val_df[\"Comment\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e278d2-3870-4abb-b2a9-40bbf79de647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that cleans text \n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"  \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub('<.*?>+', \"   \", text)\n",
    "    text = re.sub('\\n', '     ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '     ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b08c7fb-35ec-466b-9080-055ea9062239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Post</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i ve been in and out of therapy mostly in for ...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>been in regular twice a week therapy for over ...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in therapy since i was       it s been over   ...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried cbt for years and never got anywhere dbt...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>i m on       abilify and       epilim i ve bee...</td>\n",
       "      <td>formobymo</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>i was prescribed lamictal once and had a sever...</td>\n",
       "      <td>Doanya</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>quetiapine and       fluoxetine i used t...</td>\n",
       "      <td>Ddog1909</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>i was on zoloft for several years in my early ...</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>i took lamictal and lithium and i hated both</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment               Author  \\\n",
       "0    i ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1    i ve been in and out of therapy mostly in for ...          oddthing757   \n",
       "2    been in regular twice a week therapy for over ...         bedrock_BEWD   \n",
       "3    in therapy since i was       it s been over   ...  Own_Collection_8916   \n",
       "4    tried cbt for years and never got anywhere dbt...       sky-amethyst23   \n",
       "..                                                 ...                  ...   \n",
       "306  i m on       abilify and       epilim i ve bee...            formobymo   \n",
       "307  i was prescribed lamictal once and had a sever...               Doanya   \n",
       "308        quetiapine and       fluoxetine i used t...             Ddog1909   \n",
       "309  i was on zoloft for several years in my early ...           KronikHaze   \n",
       "310       i took lamictal and lithium and i hated both           KronikHaze   \n",
       "\n",
       "        Post  relevance  \n",
       "0    1bmk9m2          1  \n",
       "1    1bmk9m2          1  \n",
       "2    1bmk9m2          1  \n",
       "3    1bmk9m2          1  \n",
       "4    1bmk9m2          1  \n",
       "..       ...        ...  \n",
       "306   w5q5qv          1  \n",
       "307   w5q5qv          1  \n",
       "308   w5q5qv          1  \n",
       "309   w5q5qv          1  \n",
       "310   w5q5qv          1  \n",
       "\n",
       "[311 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply the clean_text function to the \"comment\" column of the previous data frame\n",
    "val_df[\"Comment\"] = val_df[\"Comment\"].apply(clean_text)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6590f17-c48c-41d6-99f7-7fd41508ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all of the strings containined in the \"comment\" column of the previous data frame\n",
    "list_of_comments = val_df[\"Comment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c009236-87d3-4769-8951-4b80b48cdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that will \"tokenize\" text which means breaking the string that's fed in into a list of smaller strings consisting of a single word each\n",
    "def tokenize_text(text):\n",
    "    # the text variable is the name of the list that will contain the strings \n",
    "    text = nltk.word_tokenize(text)\n",
    "    #the function returns the list \n",
    "    return text\n",
    "\n",
    "#create a function that will take in a list of tokenized text \n",
    "def tag_text(tokes):\n",
    "    # the tokes variable is assigned to a list containing tuples with the first entry being a smaller string consisting of a single word and the second entry is the part of speech of that word\n",
    "    tokes = nltk.pos_tag(tokes)\n",
    "    #the function returns the list \n",
    "    return tokes \n",
    "\n",
    "#create a function that will take in text in the form of a string\n",
    "def list_of_nouns_and_adjectives(text):\n",
    "    #creates a list of tokens for the text i.e. breaks the string up into single word strings\n",
    "    tokens = tokenize_text(text)\n",
    "    #creates a list of tagged tokens i.e. takes the list of tokens and assigns a part of speech to each token. The list is a list of ordered pairs\n",
    "    tags = tag_text(tokens)\n",
    "    #creates a dictionary of the previous list of ordered pairs (token, part of speech)\n",
    "    dic_of_tags = dict(tags)\n",
    "    #create a list comprehension that will iterate over the keys and values in the previous dictionary and returns the tokens or words that are tagged as some type of noun or adjective\n",
    "    nouns_and_adjectives = [word for word,part in dic_of_tags.items() if ((part == \"NN\") or (part == \"NNS\") or (part == \"NNP\") or (part == \"NNPS\") or (part == \"JJ\") or (part == \"JJR\") or (part == \"JJS\"))]\n",
    "    #the previous list comprehension is what the function returns \n",
    "    return nouns_and_adjectives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539a0b8b-cfb3-4aa8-ab37-65bd2d91ea8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ESK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e05ea5-cc27-40e3-a39b-fe9636bf7a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Post</th>\n",
       "      <th>relevance</th>\n",
       "      <th>Nouns and Adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, therapist, age, m, due, circumstances, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i ve been in and out of therapy mostly in for ...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, ve, therapy, past, years, helpful, hasn, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>been in regular twice a week therapy for over ...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[regular, twice, week, therapy, ten, years, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in therapy since i was       it s been over   ...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[therapy, i, years, ve, lot, motions, point, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried cbt for years and never got anywhere dbt...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[tried, cbt, years, iop, life, weekly, session...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>i m on       abilify and       epilim i ve bee...</td>\n",
       "      <td>formobymo</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, m, abilify, epilim, months, stable, few, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>i was prescribed lamictal once and had a sever...</td>\n",
       "      <td>Doanya</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, lamictal, severe, allergic, reaction, rare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>quetiapine and       fluoxetine i used t...</td>\n",
       "      <td>Ddog1909</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[quetiapine, mirtazapine, side, effects, numb,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>i was on zoloft for several years in my early ...</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, zoloft, several, years, early, worth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>i took lamictal and lithium and i hated both</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, lamictal, lithium]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment               Author  \\\n",
       "0    i ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1    i ve been in and out of therapy mostly in for ...          oddthing757   \n",
       "2    been in regular twice a week therapy for over ...         bedrock_BEWD   \n",
       "3    in therapy since i was       it s been over   ...  Own_Collection_8916   \n",
       "4    tried cbt for years and never got anywhere dbt...       sky-amethyst23   \n",
       "..                                                 ...                  ...   \n",
       "306  i m on       abilify and       epilim i ve bee...            formobymo   \n",
       "307  i was prescribed lamictal once and had a sever...               Doanya   \n",
       "308        quetiapine and       fluoxetine i used t...             Ddog1909   \n",
       "309  i was on zoloft for several years in my early ...           KronikHaze   \n",
       "310       i took lamictal and lithium and i hated both           KronikHaze   \n",
       "\n",
       "        Post  relevance                               Nouns and Adjectives  \n",
       "0    1bmk9m2          1  [i, therapist, age, m, due, circumstances, tim...  \n",
       "1    1bmk9m2          1  [i, ve, therapy, past, years, helpful, hasn, c...  \n",
       "2    1bmk9m2          1  [regular, twice, week, therapy, ten, years, ad...  \n",
       "3    1bmk9m2          1  [therapy, i, years, ve, lot, motions, point, m...  \n",
       "4    1bmk9m2          1  [tried, cbt, years, iop, life, weekly, session...  \n",
       "..       ...        ...                                                ...  \n",
       "306   w5q5qv          1  [i, m, abilify, epilim, months, stable, few, e...  \n",
       "307   w5q5qv          1  [i, lamictal, severe, allergic, reaction, rare...  \n",
       "308   w5q5qv          1  [quetiapine, mirtazapine, side, effects, numb,...  \n",
       "309   w5q5qv          1          [i, zoloft, several, years, early, worth]  \n",
       "310   w5q5qv          1                             [i, lamictal, lithium]  \n",
       "\n",
       "[311 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column in the previous data frame that lists the nouns and adjectives for each comment \n",
    "val_df[\"Nouns and Adjectives\"] = val_df[\"Comment\"].apply(list_of_nouns_and_adjectives)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7743c371-aa08-4757-9702-4bd8d79da15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parts of speech we can tag are:\n",
    "#CC coordinating conjunction\n",
    "#CD cardinal digit\n",
    "#DT determiner\n",
    "#EX existential there (like: “there is” … think of it like “there exists”)\n",
    "#FW foreign word\n",
    "#IN preposition/subordinating conjunction\n",
    "#JJ adjective ‘big’\n",
    "#JJR adjective, comparative ‘bigger’\n",
    "#JJS adjective, superlative ‘biggest’\n",
    "#LS list marker 1)\n",
    "#MD modal could, will\n",
    "#NN noun, singular ‘desk’\n",
    "#NNS noun plural ‘desks’\n",
    "#NNP proper noun, singular ‘Harrison’\n",
    "#NNPS proper noun, plural ‘Americans’\n",
    "#PDT predeterminer ‘all the kids’\n",
    "#POS possessive ending parent’s\n",
    "#PRP personal pronoun I, he, she\n",
    "#PRP$ possessive pronoun my, his, hers\n",
    "#RB adverb very, silently,\n",
    "#RBR adverb, comparative better\n",
    "#RBS adverb, superlative best\n",
    "#RP particle give up\n",
    "#TO, to go ‘to’ the store.\n",
    "#UH interjection, errrrrrrrm\n",
    "#VB verb, base form take\n",
    "#VBD verb, past tense took\n",
    "#VBG verb, gerund/present participle taking\n",
    "#VBN verb, past participle taken\n",
    "#VBP verb, sing. present, non-3d take\n",
    "#VBZ verb, 3rd person sing. present takes\n",
    "#WDT wh-determiner which\n",
    "#WP wh-pronoun who, what\n",
    "#WP$ possessive wh-pronoun whose\n",
    "#WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3342667f-f74a-4893-aaa4-35d1815dff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries, modules, and a trained model from the spacy library\n",
    "#you'll very likely need to install spacy using \"pip install spacy\"\n",
    "import spacy\n",
    "import spacy.cli \n",
    "sp_sm = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669de380-6120-45fd-856c-5bbc4ba4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that will intake some text in the form of a string\n",
    "def spacy_sm_ner(document):\n",
    "    #this function utilizes Named-entity recognition (NER) which is the process of locating named entities in unstructured text and then classifying them into predefined categories, such as person names, organizations, locations, monetary values, percentages, and time expressions\n",
    "    # this function will return a set of ordered pairs, the first entry are tokens from the text that was fed in and the second entry is some type of label for the token\n",
    "  return {(ent.text.strip(), ent.label_) for ent in sp_sm(document).ents}\n",
    "\n",
    "#define a function that will intake some text in the form of a string\n",
    "def gen_list_of_NER(text):\n",
    "    #the set of ordered pairs from spacy_sm_ner is cast as a dictionary, we take only the keys or the first entries from the tuples, and cast the collection of keys as a list\n",
    "    NERs = list(dict(spacy_sm_ner(text)).keys())\n",
    "    #the function returns the list of keys \n",
    "    return NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9edcef9-0e26-4a29-8432-3423af453fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Post</th>\n",
       "      <th>relevance</th>\n",
       "      <th>Nouns and Adjectives</th>\n",
       "      <th>NERs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, therapist, age, m, due, circumstances, tim...</td>\n",
       "      <td>[the age of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i ve been in and out of therapy mostly in for ...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, ve, therapy, past, years, helpful, hasn, c...</td>\n",
       "      <td>[the past       years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>been in regular twice a week therapy for over ...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[regular, twice, week, therapy, ten, years, ad...</td>\n",
       "      <td>[two, ten years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in therapy since i was       it s been over   ...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[therapy, i, years, ve, lot, motions, point, m...</td>\n",
       "      <td>[years, the years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried cbt for years and never got anywhere dbt...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[tried, cbt, years, iop, life, weekly, session...</td>\n",
       "      <td>[two weeks, weekly, years, about             m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>i m on       abilify and       epilim i ve bee...</td>\n",
       "      <td>formobymo</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, m, abilify, epilim, months, stable, few, e...</td>\n",
       "      <td>[months]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>i was prescribed lamictal once and had a sever...</td>\n",
       "      <td>Doanya</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, lamictal, severe, allergic, reaction, rare...</td>\n",
       "      <td>[about a year ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>quetiapine and       fluoxetine i used t...</td>\n",
       "      <td>Ddog1909</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[quetiapine, mirtazapine, side, effects, numb,...</td>\n",
       "      <td>[one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>i was on zoloft for several years in my early ...</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, zoloft, several, years, early, worth]</td>\n",
       "      <td>[several years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>i took lamictal and lithium and i hated both</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, lamictal, lithium]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment               Author  \\\n",
       "0    i ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1    i ve been in and out of therapy mostly in for ...          oddthing757   \n",
       "2    been in regular twice a week therapy for over ...         bedrock_BEWD   \n",
       "3    in therapy since i was       it s been over   ...  Own_Collection_8916   \n",
       "4    tried cbt for years and never got anywhere dbt...       sky-amethyst23   \n",
       "..                                                 ...                  ...   \n",
       "306  i m on       abilify and       epilim i ve bee...            formobymo   \n",
       "307  i was prescribed lamictal once and had a sever...               Doanya   \n",
       "308        quetiapine and       fluoxetine i used t...             Ddog1909   \n",
       "309  i was on zoloft for several years in my early ...           KronikHaze   \n",
       "310       i took lamictal and lithium and i hated both           KronikHaze   \n",
       "\n",
       "        Post  relevance                               Nouns and Adjectives  \\\n",
       "0    1bmk9m2          1  [i, therapist, age, m, due, circumstances, tim...   \n",
       "1    1bmk9m2          1  [i, ve, therapy, past, years, helpful, hasn, c...   \n",
       "2    1bmk9m2          1  [regular, twice, week, therapy, ten, years, ad...   \n",
       "3    1bmk9m2          1  [therapy, i, years, ve, lot, motions, point, m...   \n",
       "4    1bmk9m2          1  [tried, cbt, years, iop, life, weekly, session...   \n",
       "..       ...        ...                                                ...   \n",
       "306   w5q5qv          1  [i, m, abilify, epilim, months, stable, few, e...   \n",
       "307   w5q5qv          1  [i, lamictal, severe, allergic, reaction, rare...   \n",
       "308   w5q5qv          1  [quetiapine, mirtazapine, side, effects, numb,...   \n",
       "309   w5q5qv          1          [i, zoloft, several, years, early, worth]   \n",
       "310   w5q5qv          1                             [i, lamictal, lithium]   \n",
       "\n",
       "                                                  NERs  \n",
       "0                                         [the age of]  \n",
       "1                               [the past       years]  \n",
       "2                                     [two, ten years]  \n",
       "3                                   [years, the years]  \n",
       "4    [two weeks, weekly, years, about             m...  \n",
       "..                                                 ...  \n",
       "306                                           [months]  \n",
       "307                                 [about a year ago]  \n",
       "308                                              [one]  \n",
       "309                                    [several years]  \n",
       "310                                                 []  \n",
       "\n",
       "[311 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column in the previous data frame that lists the NERs for each comment\n",
    "val_df[\"NERs\"] = val_df[\"Comment\"].apply(gen_list_of_NER)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a71964c5-15f8-4903-b0c4-4a832e78a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The recognized entities are:\n",
    "#PERSON:      People, including fictional.\n",
    "#NORP:        Nationalities or religious or political groups.\n",
    "#FAC:         Buildings, airports, highways, bridges, etc.\n",
    "#ORG:         Companies, agencies, institutions, etc.\n",
    "#GPE:         Countries, cities, states.\n",
    "#LOC:         Non-GPE locations, mountain ranges, bodies of water.\n",
    "#PRODUCT:     Objects, vehicles, foods, etc. (Not services.)\n",
    "#EVENT:       Named hurricanes, battles, wars, sports events, etc.\n",
    "#WORK_OF_ART: Titles of books, songs, etc.\n",
    "#LAW:         Named documents made into laws.\n",
    "#LANGUAGE:    Any named language.\n",
    "#DATE:        Absolute or relative dates or periods.\n",
    "#TIME:        Times smaller than a day.\n",
    "#PERCENT:     Percentage, including ”%“.\n",
    "#MONEY:       Monetary values, including unit.\n",
    "#QUANTITY:    Measurements, as of weight or distance.\n",
    "#ORDINAL:     “first”, “second”, etc.\n",
    "#CARDINAL:    Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdf32edc-b89f-42f5-b03a-77f09d1f5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting drug-named-entity-recognition\n",
      "  Downloading drug_named_entity_recognition-1.0.3-py3-none-any.whl.metadata (17 kB)\n",
      "Downloading drug_named_entity_recognition-1.0.3-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.3/1.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.0/1.1 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: drug-named-entity-recognition\n",
      "Successfully installed drug-named-entity-recognition-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install drug-named-entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5570f32-ed7a-4d05-8615-28c7199b35ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'name': 'Acetaminophen', 'synonyms': {'Hydroxyacetanilide', 'Acephen', 'Acetominophen', 'Algotropyl', 'Acetaminophen', 'Acetamidophenol', 'Acenol', 'Paracetamol', 'Datril', 'Acamol', 'Actamin', 'Paracetamolum', 'Ofirmev', 'Panadol', 'Acetaco', 'Tylenol'}, 'medline_plus_id': 'a621016', 'generic_names': ['Acetaminophen'], 'mesh_id': 'D058633', 'drugbank_id': 'DB00316', 'wikipedia_url': 'https://en.wikipedia.org/wiki/Paracetamol'}, 2, 2)]\n"
     ]
    }
   ],
   "source": [
    "#you'll likely need to install the following with \"pip install drug-named-entity-recognition\"\n",
    "#this library and module will allow us to search strings for the names of drugs \n",
    "from drug_named_entity_recognition import find_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1584bd-d71b-4bd4-ac4a-6d83fa15dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that takes in some text as a string\n",
    "def list_of_drugs_in_text(corpus):\n",
    "    #create an empty list \n",
    "    list_of_drugs = []  \n",
    "    #use the find_drugs function to return a list of triples where the first entry is a dictionary stating the name of a drug and information on that drug, the split function tokenizes the text, and is_ignore_case will enable the function to ignore the case of any drug name \n",
    "    drugs_list = find_drugs(corpus.split(\" \"),is_ignore_case=True)\n",
    "    #check to make sure at least one drug is mentioned\n",
    "    if drugs_list != []:\n",
    "        #If it is, we split up the triple into three different lists \n",
    "        list_of_dicts, listn1, listn2 = zip(*drugs_list)\n",
    "        #we create a list of the first entries in the triples which should be dictionaries \n",
    "        drug_info_list = list(list_of_dicts)\n",
    "        #for each dictionary in our list \n",
    "        for dict1 in drug_info_list: \n",
    "            #we append the name of the drug which is the first value in each dictionary to the empty list we created\n",
    "            list_of_drugs.append(dict1['name'])\n",
    "    #if there are no drugs mentioned\n",
    "    else:\n",
    "        #we don't do anything, and the list_of_drugs will remain empty\n",
    "       pass \n",
    "    #the function will return a list of the mentioned drugs in the text \n",
    "    return list_of_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f04bce-6e50-4af0-ba18-6aeff6a18cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Author</th>\n",
       "      <th>Post</th>\n",
       "      <th>relevance</th>\n",
       "      <th>Nouns and Adjectives</th>\n",
       "      <th>NERs</th>\n",
       "      <th>Drugs Mentioned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ve been seeing a therapist since the age of ...</td>\n",
       "      <td>ChocCoveredSarcasm</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, therapist, age, m, due, circumstances, tim...</td>\n",
       "      <td>[the age of]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i ve been in and out of therapy mostly in for ...</td>\n",
       "      <td>oddthing757</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, ve, therapy, past, years, helpful, hasn, c...</td>\n",
       "      <td>[the past       years]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>been in regular twice a week therapy for over ...</td>\n",
       "      <td>bedrock_BEWD</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[regular, twice, week, therapy, ten, years, ad...</td>\n",
       "      <td>[two, ten years]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in therapy since i was       it s been over   ...</td>\n",
       "      <td>Own_Collection_8916</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[therapy, i, years, ve, lot, motions, point, m...</td>\n",
       "      <td>[years, the years]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tried cbt for years and never got anywhere dbt...</td>\n",
       "      <td>sky-amethyst23</td>\n",
       "      <td>1bmk9m2</td>\n",
       "      <td>1</td>\n",
       "      <td>[tried, cbt, years, iop, life, weekly, session...</td>\n",
       "      <td>[two weeks, weekly, years, about             m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>i m on       abilify and       epilim i ve bee...</td>\n",
       "      <td>formobymo</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, m, abilify, epilim, months, stable, few, e...</td>\n",
       "      <td>[months]</td>\n",
       "      <td>[Aripiprazole]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>i was prescribed lamictal once and had a sever...</td>\n",
       "      <td>Doanya</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, lamictal, severe, allergic, reaction, rare...</td>\n",
       "      <td>[about a year ago]</td>\n",
       "      <td>[Lamotrigine, Lamotrigine, Duloxetine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>quetiapine and       fluoxetine i used t...</td>\n",
       "      <td>Ddog1909</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[quetiapine, mirtazapine, side, effects, numb,...</td>\n",
       "      <td>[one]</td>\n",
       "      <td>[Quetiapine, Fluoxetine, Fluoxetine, Mirtazapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>i was on zoloft for several years in my early ...</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, zoloft, several, years, early, worth]</td>\n",
       "      <td>[several years]</td>\n",
       "      <td>[Sertraline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>i took lamictal and lithium and i hated both</td>\n",
       "      <td>KronikHaze</td>\n",
       "      <td>w5q5qv</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, lamictal, lithium]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Lamotrigine]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment               Author  \\\n",
       "0    i ve been seeing a therapist since the age of ...   ChocCoveredSarcasm   \n",
       "1    i ve been in and out of therapy mostly in for ...          oddthing757   \n",
       "2    been in regular twice a week therapy for over ...         bedrock_BEWD   \n",
       "3    in therapy since i was       it s been over   ...  Own_Collection_8916   \n",
       "4    tried cbt for years and never got anywhere dbt...       sky-amethyst23   \n",
       "..                                                 ...                  ...   \n",
       "306  i m on       abilify and       epilim i ve bee...            formobymo   \n",
       "307  i was prescribed lamictal once and had a sever...               Doanya   \n",
       "308        quetiapine and       fluoxetine i used t...             Ddog1909   \n",
       "309  i was on zoloft for several years in my early ...           KronikHaze   \n",
       "310       i took lamictal and lithium and i hated both           KronikHaze   \n",
       "\n",
       "        Post  relevance                               Nouns and Adjectives  \\\n",
       "0    1bmk9m2          1  [i, therapist, age, m, due, circumstances, tim...   \n",
       "1    1bmk9m2          1  [i, ve, therapy, past, years, helpful, hasn, c...   \n",
       "2    1bmk9m2          1  [regular, twice, week, therapy, ten, years, ad...   \n",
       "3    1bmk9m2          1  [therapy, i, years, ve, lot, motions, point, m...   \n",
       "4    1bmk9m2          1  [tried, cbt, years, iop, life, weekly, session...   \n",
       "..       ...        ...                                                ...   \n",
       "306   w5q5qv          1  [i, m, abilify, epilim, months, stable, few, e...   \n",
       "307   w5q5qv          1  [i, lamictal, severe, allergic, reaction, rare...   \n",
       "308   w5q5qv          1  [quetiapine, mirtazapine, side, effects, numb,...   \n",
       "309   w5q5qv          1          [i, zoloft, several, years, early, worth]   \n",
       "310   w5q5qv          1                             [i, lamictal, lithium]   \n",
       "\n",
       "                                                  NERs  \\\n",
       "0                                         [the age of]   \n",
       "1                               [the past       years]   \n",
       "2                                     [two, ten years]   \n",
       "3                                   [years, the years]   \n",
       "4    [two weeks, weekly, years, about             m...   \n",
       "..                                                 ...   \n",
       "306                                           [months]   \n",
       "307                                 [about a year ago]   \n",
       "308                                              [one]   \n",
       "309                                    [several years]   \n",
       "310                                                 []   \n",
       "\n",
       "                                       Drugs Mentioned  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3                                                   []  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "306                                     [Aripiprazole]  \n",
       "307             [Lamotrigine, Lamotrigine, Duloxetine]  \n",
       "308  [Quetiapine, Fluoxetine, Fluoxetine, Mirtazapi...  \n",
       "309                                       [Sertraline]  \n",
       "310                                      [Lamotrigine]  \n",
       "\n",
       "[311 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column in the previous data frame that lists the Drugs Mentioned for each comment\n",
    "val_df[\"Drugs Mentioned\"] = val_df[\"Comment\"].apply(list_of_drugs_in_text)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c296a11-7e4e-419c-a18f-86682c8500e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I believe any drug that appears on wikipedia can be checked for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d77af2-2f24-4224-a2a9-d43e8cab3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"val_ner_df.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bdc4830-14c1-45ff-9c09-23a0fb7fae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cd539-b228-4f92-9a62-c7c54cca0b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "erdos_may_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
